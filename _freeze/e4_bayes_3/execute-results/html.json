{
  "hash": "f17eeac3957b96d4f4ad72dba5a20918",
  "result": {
    "markdown": "---\ntitle: \"Week #4\"\nauthor: \"Adrian Correndo & Josefina Lacasa\"\nformat:\n  html:\n    fontsize: 0.8em\n    linestretch: 1\n---\n\n\n# Introduction to Bayesian Stats #3\n\nThis article is a review and final example to wrap up our brief introduction to Bayesian data analysis.\n\n## 01. CONCEPTS REVIEW\n\n::: callout-important\nUnder the Bayesian approach we consider probability as an expression of the degree of certainty (or uncertainty) about a process or parameter.\n:::\n\n::: callout-note\nREMEMBER!\n\nThe structure of the Bayesian theory is similar to the Human Logic process. It is all about updating knowledge:\n\n\\(i\\) we have some data,\n\n\\(ii\\) we have beliefs about the underlying process,\n\n\\(iii\\) combining both, we can update our beliefs.\n:::\n\n### i. The Bayes Theorem\n\n$$ P(\\theta | x)  = P(\\theta) * \\frac{P(x|\\theta)}{P(x)}$$ where $\\theta$ is the parameter of interest, $x$ is the data, and \"\\|\" means \"conditional\".\n\n$$ Knowledge~after  = Knowledge~before * updating~factor$$ $$ Posterior~distribution  = Prior~distribution * \\frac{Likelihood} {Marginal Likelihood} $$\n\n### ii. Hierarchical structure\n\nYou may have heard multiple times about Bayesian Hierarchical Framework or Bayesian Hierarchical Modelling. This simply means that our model is compound by multiple nested levels (hierarchy) where we account for random effects. Actually, they are usually also referred as multi-level models (Hooten & Hefley, 2019). There are two relevant concepts here to derive the posterior distributions:\n\n1.  **Hyper-parameters** are the parameters of the prior distribution. For example, if we have $Y|\\mu \\sim N(\\mu, \\sigma^2)$, with $\\mu = \\beta_1 *X$ as the \"top-level\" parameter describing the process model, where $\\beta_1$ is the hyper-parameter.\n\n2.  **Hyper-priors** are the distributions of the hyper-parameters. For example, $\\beta_1 \\sim N(\\mu_{\\beta_1}, \\sigma^2_{\\beta_1})$ is the hyper-prior of $\\beta_1$\n\nBasically, we have a set of layers (see Kwag & Hu, 2019):\n\nLayer 1: the **data** layer $$ y_i|\\mu_i, \\beta_1 \\sim P(y_i|\\mu_i, \\beta_1)$$\n\nLayer 2: the **process** layer $$ \\mu_i| \\beta_1 \\sim P(\\mu_i|\\beta_1)$$\n\nLayer 3: the **prior** layer $$ \\beta_1 \\sim P(\\beta_1) = $$\n\n$$ \\beta_1 \\sim N(\\mu_{\\beta_1}, \\sigma^2_{\\beta_1})$$\n\n### Posterior distribution\n\nFollowing the example above, the posterior $P(\\mu_i, \\beta_1|y_i)$ is a probability density function that quantifies the \"uncertainty\" about $y_i$ within a specific model after the data collection as follows:\n\n$$ P(\\mu_i, \\beta_1|y_i)  \\propto P(y_i|\\mu_i, \\beta_1)*P(\\mu_i|\\beta_1) * P(\\beta_1) $$ where $y_i$ represents the data, and $\\mu_i$ is the process model dependent on the random variable $\\beta_1$.\n\nIn practice, however, we never know this specific function. So what we do is to create multiple simulations (the MCMC) given the prior/s and the data, and then summarizing those simulations (e.g. obtaining credible intervals at variable probability levels, for example, 95%).\n\n### References\n\nHooten, M.B., and Hefley, T.J., 2019. Chaper 19: Hierarchical Models. Bringing Bayesian Models to Life. <https://doi.org/10.1201/9780429243653>\n\nKwag, S., Ju, B.S. Application of a Bayesian hierarchical model to system identification of structural parameters. *Engineering with Computers* **36**, 455--474 (2020). <https://doi.org/10.1007/s00366-019-00708-1>\n\n## 02. EXAMPLE CODE\n\n### Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(easypackages)\npackages(\"dplyr\", \"tidyr\", \"purrr\", \"tibble\")\npackages(\"readxl\", \"stringr\")\npackages(\"ggplot2\")\npackages(\"nlme\", \"car\", \"emmeans\", \"multcomp\", \"multcompView\")\npackages(\"brms\", \"tidybayes\", \"performance\")\n\n# Data\n# Corn yield response to N rates somewhere in KS\ndata <- read_excel(\"data/cropyield.xlsx\") %>%\n  mutate(BLOCK = rep(c(1,2,3,4), nrow(.)/4))\n```\n:::\n\n\n### a. Frequentist with lme\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Analisis, no intercept (0 + ...)\nyield_lme <- data %>% \n  group_by(PHASE) %>% nest() %>% \n  mutate(model = map(data,\n                     ~lme(GY_bu ~ 0 + as.factor(TREAT), \n                          random = ~1|BLOCK, data=.)))\n\n# Extract the model\ncorn_lme <- yield_lme[[\"model\"]][[1]]\n\ncorn_lme\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: . \n  Log-restricted-likelihood: -67.70787\n  Fixed: GY_bu ~ 0 + as.factor(TREAT) \n  as.factor(TREAT)0  as.factor(TREAT)60 as.factor(TREAT)120 as.factor(TREAT)180 \n           137.7226            183.1838            215.1319            233.2673 \nas.factor(TREAT)240 \n           236.2163 \n\nRandom effects:\n Formula: ~1 | BLOCK\n        (Intercept) Residual\nStdDev:     1.65409 17.46253\n\nNumber of Observations: 20\nNumber of Groups: 4 \n```\n:::\n\n```{.r .cell-code}\n# ANOVA\nAnova(corn_lme, type = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: GY_bu\n                  Chisq Df Pr(>Chisq)    \nas.factor(TREAT) 2627.3  5  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n#### Multiple comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Multiple comparison\ncorn_lme_mc<-emmeans(corn_lme, ~ TREAT)\n\ncorn_lme_means <- as.data.frame(\n  cld(corn_lme_mc, decreasing = TRUE, details=FALSE, reversed=TRUE, alpha=0.05,  \n      adjust = \"tukey\", Letters=LETTERS))\n\ncorn_lme_means\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n TREAT   emmean       SE df lower.CL upper.CL .group\n   240 236.2163 8.770349 12 209.5232 262.9093  A    \n   180 233.2673 8.808076 12 206.4594 260.0751  A    \n   120 215.1319 8.789152 12 188.3816 241.8822  AB   \n    60 183.1838 8.770349 12 156.4907 209.8768   B   \n     0 137.7226 8.789152 12 110.9724 164.4729    C  \n\nDegrees-of-freedom method: containment \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 5 estimates \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n:::\n\n\n### b. Bayesian with brms\n\n#### i. MCMC pars\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set up pars\nWU = 1000\nIT = 3000\nTH = 5\nCH = 4\nAD = 0.99\n```\n:::\n\n\n#### ii. Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Analysis\ncorn_brms <- data %>%\n  mutate(TREAT = as.factor(TREAT)) %>%\n  dplyr::group_by(PHASE) %>% tidyr::nest() %>%\n  mutate(model = map(data,\n                     ~brms::brm(\n                       #Priors\n                       # Priors\n                       prior = c(\n    # Prior of the Yield (effect from 0) notice there is no intercept\n    prior(prior = 'normal(100,100)', class = \"b\") ),\n    # If using the intercept\n      # prior(prior = 'normal(80,80)', class = \"Intercept\") ),\n    # Careful with \"treatment\" prior, cause it's not yield now (it's response)\n      # prior(prior = 'normal(100,100)', class = \"Intercept\") ),\n    \n    # Formula\n    # With 0 as the intercept.\n    formula = bf(GY_bu ~  0 + TREAT + (1|BLOCK)),\n  data = ., sample_prior = \"yes\",\n  family = gaussian(link = 'identity'),\n  control = list(adapt_delta = AD),\n  warmup = WU, iter = IT, thin = TH,\n  chains = CH, cores = CH,\n  init_r = 0.1, seed = 1)  ) )\n```\n:::\n\n\n#### iii. Check the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot\nplot(corn_brms$model[[1]]) \n```\n\n::: {.cell-output-display}\n![](e4_bayes_3_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](e4_bayes_3_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Check the posteriors \n# (yrep, blue lines) to see how the model simulates your data (y, black line)\npp_check(corn_brms$model[[1]], nsamples = 200)\n```\n\n::: {.cell-output-display}\n![](e4_bayes_3_files/figure-html/unnamed-chunk-6-3.png){width=672}\n:::\n:::\n\n\n#### iv. Model summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summary\nsummary(corn_brms$model[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: GY_bu ~ 0 + TREAT + (1 | BLOCK) \n   Data: . (Number of observations: 20) \n  Draws: 4 chains, each with iter = 3000; warmup = 1000; thin = 5;\n         total post-warmup draws = 1600\n\nMultilevel Hyperparameters:\n~BLOCK (Number of levels: 4) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)    11.63     11.47     0.39    40.79 1.00     1043     1270\n\nRegression Coefficients:\n         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nTREAT0     135.48     12.55   108.68   158.07 1.00     1240     1294\nTREAT60    180.63     12.62   154.21   202.90 1.00     1205      928\nTREAT120   214.21     12.49   188.26   236.34 1.00     1287     1048\nTREAT180   227.40     13.54   197.32   250.66 1.00     1145      942\nTREAT240   232.94     12.53   206.66   255.53 1.00     1192      946\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    18.60      4.03    12.65    28.50 1.00     1526     1559\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n# Performance\nperformance::performance(corn_brms$model[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nELPD    | ELPD_SE |   LOOIC | LOOIC_SE |    WAIC |    R2 | R2 (marg.) | R2 (adj.) | R2_adjusted_marginal |   ICC |   RMSE\n-------------------------------------------------------------------------------------------------------------------------\n-90.511 |   2.534 | 181.022 |    5.068 | 179.516 | 0.841 |      0.827 |     0.747 |               -1.000 | 0.281 | 13.978\n```\n:::\n:::\n\n\n#### v. Extract posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pass model draws to a dataframe\ncorn_brms_draws <- as.data.frame(corn_brms$model[[1]]) %>% \n  # Rename for simplicity\n  rename_with( ~ str_replace(.x, \"b_TREAT\", \"N\"))\n\n\n# Create a df with posterior of treatment differences\ncontrast_tibble <-\ncorn_brms_draws %>%\n  # FOr model with GY_bu ~ 0 + TREAT\n   mutate(# Rates vs. Check\n          `A - N60_N0` = N60 - N0,\n          `B - N120_N0` = N120 - N0,\n          `C - N180_N0` = N240 - N0,\n          `D - N240_N0` = N240 - N0,\n          .before = 1) %>% \n  dplyr::select(1:4) %>%\n  pivot_longer(cols = everything(),\n               values_to = \"value\", names_to = \"contrast\")\n\n# Contrast summary\ncontrast_summary <- \n  contrast_tibble %>% group_by(contrast) %>% \n             summarise(median = median(value),\n                       q025 = quantile(value, prob = 0.025),\n                       q975 = quantile(value, prob = 0.975) )\n```\n:::\n\n\n#### vi. Posteriors Summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot\ncontrast_plot <- contrast_tibble %>%\n  ggplot(aes(x = value, color = contrast))+\n  geom_histogram(aes(fill = contrast), color = \"grey25\")+\n  # Add median\n  geom_vline(data = contrast_summary, aes(xintercept = median),\n             linetype = 2, size = 0.75)+\n  # Add limits of credible intervals\n  geom_vline(data = contrast_summary, aes(xintercept = q025),\n             linetype = 3, size = 0.25)+\n  geom_vline(data = contrast_summary, aes(xintercept = q975), \n             linetype = 3, size = 0.25)+\n  # Add line at 0 bu/ac.\n  geom_vline(data = contrast_summary, aes(xintercept = 0), \n             linetype = 1, size = 0.5)+\n  facet_wrap(~contrast, nrow = 2)+\n  labs(title = \"Posteriors of comparisons\",\n       x = \"Difference (bu/ac.)\", y = \"Density\")+\n  theme_tidybayes()+\n  theme(legend.position = \"none\")\n\ncontrast_plot\n```\n\n::: {.cell-output-display}\n![](e4_bayes_3_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "e4_bayes_3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}