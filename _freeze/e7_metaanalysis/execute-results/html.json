{
  "hash": "5fcf35de4d51d1cfb3479bd062bd2d3b",
  "result": {
    "markdown": "---\ntitle: \"Week #8 | Systematic reviews procedures in R\"\nsubtitle: \"A compilation of methods and funtions for meta-analytic data in R\"\nauthor: \"Nicolas Giordano\"\ndate: 10-24-2022\nabstract-title: 'Summary'\nabstract: 'Lack of agreement in scientific findings derives in the need of exploring meta-analytic techniques. Systematic reviews tend to provide an UNBIASED method for answering specific questions. This code glimpses my personal experience while conducting a meta-analysis. I expect to help by sharing my own mistakes but also interesting functions to make meta-analytic research more friendly and approachable.'\n\nformat:\n  html:\n    code-tools: true\n    code-fold: true\n    code-summary: 'Show code'\n    code-link: true\n    theme: united\ntoc: true\ntoc-title: 'Contents'\ntoc-depth: 4\ntoc-location: left\nnumber-sections: false\nhighlight-style: pygments\nsmooth-scroll: true\n---\n\n\n## Data Collection\n\n### SCOPUS QUERYS\n\nLining out the search query one step at a time for REPLICABILITY\n\n[SCOPUS advanced search](https://www.scopus.com/search/form.uri?display=advanced)\n\nSOURCE-ID (78796 OR 59988 OR 38753 OR 15639) AND\n\nTITLE( (wheat OR nitrogen) AND (protein OR yield) ) AND\n\nPUBYEAR \\> 1980\n\n### How we download a list of abstracts all at once?\n\n1.  Select all articles\n\n2.  Click on \"Export CSV\"\n\n3.  From the bulleted list select all those features you will need for further exploration of articles (Title, authors, publication year, abstract, etc)\n\n4.  Download files with the extension *.ris*, which can be handled by *revtools* package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE,  message = FALSE,  warning = FALSE,  tidy = TRUE)\n# Required packages\n#install.packages(\"easypackages\")\nlibrary(easypackages)\npackages(\"tidyverse\")\npackages(\"revtools\")\npackages(\"readxl\")\npackages(\"janitor\")\npackages(\"bayestestR\")\npackages(\"mi\")\npackages(\"metafor\")\npackages(\"multidplyr\")\nsource(\"assets/class07/functions_sys_reviews.R\")\n`%nin%` <- Negate(`%in%`)\n```\n:::\n\n\n### 1. First article screening\n\nQuery -\n\nSOURCE-ID (78796 OR 59988 OR 38753 OR 15639) AND\n\n**TITLE**( (wheat OR nitrogen) AND (protein OR yield) ) AND\n\nPUBYEAR \\> 1980\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath = \"assets/class07/articles/articles already searched/\"\n\nfiles <- list.files(path = path, pattern = \"*.ris\")\n\nfirst_search = load_bibliography(path = path, files = files)\n```\n:::\n\n\n### 2. Second article screening\n\nQuery -\n\nSOURCE-ID (78796 OR 59988 OR 38753 OR 15639) AND\n\n**TITLE-ABS-KEY**( (wheat OR nitrogen) AND (protein OR yield) ) AND\n\nPUBYEAR \\> 1980\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath2 = \"assets/class07/articles/new search/\"\n\nfiles2 <- list.files(path = path2, pattern = \"*.ris\")\n\nsecond_search = load_bibliography(path = path2, files = files2)\n\n#View(second_search)\n```\n:::\n\n\n### 3. Merge the first and second screenings and get only the articles that WERE NOT SCREENED YET.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_final = anti_join(second_search, first_search)\n\nwrite.csv(x = df_final, file = \"assets/class07/articles/articles_search_final.csv\")\n```\n:::\n\n\n### 4. Run revtools shiny app\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#screen_abstracts(max_file_size = 10)\n```\n:::\n\n\n# HANDS ON\n\nIn this section we will:\n\n1.  Impute missing data using *mi* package\n\n2.  Calculate effect sizes\n\n3.  Run a pooled effects model\n\n4.  Test potential factor driving the size of the observed effects .\n\n5.  We will utilize bootstrapping techniques and parallel processing for making the code run faster.\n\n6.  Produce a forest plot.\n\n## Meta-analytic data\n\nAs an example we will use data from split N application in with crops. This meta analysis is comparing whether applying N on a single dose or splitting(2 splits, 3 splits or just split, regardless or number of splits) has any effect on wheat yields.\n\nIt does also compared how different factors (called moderators if categorical) affect the size of the observed effects.\n\nThe article can be find here [Hu et al 2021](https://www.sciencedirect.com/science/article/pii/S0167198721001847)\n\n### Load data and wrangling\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata = read_excel(\"assets/class07/example_data.xlsx\", skip = 2) %>% \n  janitor::clean_names()\n```\n:::\n\n\n### 1. Imputation of missing data\n\n#### 1.1) Run multiple.imputation()\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn.imp = 10\ndf.for.imp = data %>% \n  select(contains(c(\"yield\", \"sd_\")))\n\ndata.imp = data %>% \n  cbind(# Imputation of SD of grain yield when applying N all at once\n        multiple.imputation(n.imp = n.imp, df.variables = df.for.imp, impute.var = \"sd_1\", var.name = \"sd1_imp\"),\n        # Imputation of SD of grain yield when splitting N twice\n        multiple.imputation(n.imp = n.imp, df.variables = df.for.imp, impute.var = \"sd_2\", var.name = \"sd2_imp\")\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNOTE: In the following pairs of variables, the missingness pattern of the second is a subset of the first.\n Please verify whether they are in fact logically distinct variables.\n     [,1]   [,2]     \n[1,] \"sd_3\" \"log_VAR\"\n[2,] \"sd_4\" \"log_VAR\"\nNOTE: In the following pairs of variables, the missingness pattern of the second is a subset of the first.\n Please verify whether they are in fact logically distinct variables.\n     [,1]   [,2]     \n[1,] \"sd_3\" \"log_VAR\"\n[2,] \"sd_4\" \"log_VAR\"\n```\n:::\n:::\n\n\n### 2. Calculate effect sizes & pooled sample variance\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.imp_es = \n  data.imp %>%\n  drop_na(yield_kg_ha_1,reps_1, reps_2, sd1_imp, sd2_imp, yield_kg_ha_2 ) %>% \n  transmute(\n            PAPER_ID = no, \n            TEXTURE = soil_texture, \n            AI = aridity_index, \n            WHEAT_TYPE = whea_type, \n            TILLAGE = tillage,\n            # Response Ratio\n            RR = log(yield_kg_ha_2/yield_kg_ha_1),\n            # Calculate pooled sampling variance\n            VAR = pooled.var(sd.treated = sd2_imp, sd.control  = sd1_imp, \n                          n.control = reps_1, n.treated = reps_2,\n                          m.treated = yield_kg_ha_1, m.control = yield_kg_ha_2),\n            # Weights\n            W = 1/VAR\n            )\n```\n:::\n\n\n### 3. Run pooled model - intercept only\n\nYou can find more info about I2 statistic here: [Borenstein 2015](https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1230), [Higgins and Thompson 2002](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.1186)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run pooled model\nmod = rma(yi = RR,\n          vi = VAR,\n          weights = W,\n          #control = list(optimizer=\"optimParallel\", ncpus=3),\n          data = data.imp_es)\n\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nRandom-Effects Model (k = 1311; tau^2 estimator: REML)\n\n    logLik    deviance         AIC         BIC        AICc   \n 1054.4785  -2108.9571  -2104.9571  -2094.6015  -2104.9479   \n\ntau^2 (estimated amount of total heterogeneity): 0.0083 (SE = 0.0004)\ntau (square root of estimated tau^2 value):      0.0913\nI^2 (total heterogeneity / total variability):   92.40%\nH^2 (total variability / sampling variability):  13.16\n\nTest for Heterogeneity:\nQ(df = 1310) = 14454.8167, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.0249  0.0046  5.3755  <.0001  0.0158  0.0339  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# Back transformation\ntrans(coef(mod))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n intrcpt \n2.517654 \n```\n:::\n\n```{.r .cell-code}\n# I squared statistic\nmod$I2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 92.39838\n```\n:::\n:::\n\n\n### 4. Influential Studies Diagnosis\n\nWhen certain studies excert a strong influence in the model output they are consider influential. An influential case can be diagnosed when the cook's D value for a given study is x 3 times greater than the average Cook's D of the whole data. Use this citation for the this procedure: [Cook 1977](https://www.tandfonline.com/doi/abs/10.1080/01621459.1979.10481634), [Stephanie 2016](https://www.statisticshowto.com/cooks-distance/)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cooks.distance.rma.uni(model = mod, progbar = T) %>% \n#   saveRDS(\"output/cooksD_diagnosis.RData\")\n# \n# plot(readRDS(\"output/cooksD_diagnosis.RData\"))\n\ninfluential_cases = c(2, 3, 4)\n\ndata.imp_es_ic = \n  data.imp_es %>% \n  mutate(W = case_when(PAPER_ID %in% influential_cases ~ 0, T~W))\n```\n:::\n\n\n### 5. Run non-bootstrapped model\n\nWeight of influential studies is set to zero\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2 = rma(yi = RR,\n          vi = VAR,\n          weights = W,\n          mods = ~ 0 + TEXTURE,\n          #control = list(optimizer=\"optimParallel\", ncpus=3),\n          data = data.imp_es_ic)\n```\n:::\n\n\n### 6. Run bootstrapped models\n\nCitation: [Adams et al 1997](https://www.scopus.com/record/display.uri?eid=2-s2.0-0030613897&origin=inward)\n\n#### 6.1) Pooled effects, intercept only model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#bootstrap_rma(data = data.imp_es_ic, response_variable = \"RR\",moderator = NA, boot_num = 16, cores = 16)\n```\n:::\n\n\n#### 6.2) Test potential moderators\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#bootstrap_rma(data = data.imp_es_ic, response_variable = \"RR\",moderator = \"TEXTURE\", boot_num = 16, cores = 16)\n```\n:::\n\n\n#### 6.3) Summarize bootstraps\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf.plot = summarise_bootstraps(readRDS(\"assets/class07/output/RR_TEXTURE_mod.RData\"))\n```\n:::\n\n\n#### 6.4) Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf.plot %>% \n  ggplot()+\n  geom_linerange(aes(ymin = trans(ESTIM_q975), ymax = trans(ESTIM_q025), x = MOD), size = 1)+\n  geom_point(aes(x = MOD, y = trans(ESTIM_q500), fill = MOD), shape = 21, size = 6, stroke = 1.2)+\n  coord_flip()+ \n  labs(x = \"Soil Texture\", y = \"Effect Size (%)\")+\n  guides(fill = \"none\")+\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](e7_metaanalysis_files/figure-html/plot-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "e7_metaanalysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}